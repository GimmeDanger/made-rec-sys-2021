{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df56dce",
   "metadata": {},
   "source": [
    "# LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06918a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f65b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from interaction_table import InteractionTable\n",
    "from h3_index import H3Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94647b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_data import preprocess_orders_and_clicks, additional_filtration_orders_and_clicks\n",
    "from user_features import generate_user_features"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3910e0aa",
   "metadata": {},
   "source": [
    "def get_clicks():\n",
    "    path = '../data/click.parquet'\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "def get_orders():\n",
    "    path = '../data/orders.parquet'\n",
    "    df = pd.read_parquet(path)\n",
    "    path = '../data/clicks.parquet'\n",
    "    clicks = pd.read_parquet(path)\n",
    "    df, _ = additional_filtration_orders_and_clicks(df, clicks, 0)\n",
    "    df = df.rename(columns={\"customer_id\": \"user_id\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0b84c36",
   "metadata": {},
   "source": [
    "path = '../data/orders.parquet'\n",
    "orders = pd.read_parquet(path)\n",
    "path = '../data/clicks.parquet'\n",
    "clicks = pd.read_parquet(path)\n",
    "\n",
    "user_features = generate_user_features(orders, clicks)\n",
    "\n",
    "orders, clicks = additional_filtration_orders_and_clicks(orders, clicks, 0)\n",
    "orders = orders.rename(columns={\"customer_id\": \"user_id\"})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "462a1de0",
   "metadata": {},
   "source": [
    "user_features.to_parquet(\"../data/user_features.parquet\")\n",
    "orders.to_parquet(\"../data/orders_filtered.parquet\")\n",
    "clicks.to_parquet(\"../data/clicks_filtered.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee8f17c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_parquet(\"../data/orders_filtered.parquet\")\n",
    "user_features = pd.read_parquet(\"../data/user_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a9f1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders weighter: use user avg orders per chain as weight\n",
      "            user_id      chain_id        weight\n",
      "count  3.106486e+06  3.106486e+06  3.106486e+06\n",
      "mean   3.666636e+07  3.212015e+04  1.755490e+00\n",
      "std    2.148159e+07  1.517362e+04  8.203714e+01\n",
      "min    0.000000e+00  9.000000e+00  1.000000e+00\n",
      "25%    1.143635e+07  2.714700e+04  1.000000e+00\n",
      "50%    3.991074e+07  3.007500e+04  1.000000e+00\n",
      "75%    5.175972e+07  4.451900e+04  2.000000e+00\n",
      "max    7.213893e+07  7.332400e+04  1.444470e+05\n",
      "Orders df weighted: size=3106486, uniq_users=1394062, uniq_chains=7792\n"
     ]
    }
   ],
   "source": [
    "interactions = InteractionTable(orders, None, alpha=0, test_slice=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df7f5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "833957b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# возьмем все фичи и сравним со средним\n",
    "user_features_sparse = scipy.sparse.csr_matrix(\n",
    "    (\n",
    "        user_features.loc[interactions.user_to_index.keys()] \n",
    "        - user_features.loc[interactions.user_to_index.keys()].mean()\n",
    "        > 0\n",
    "    ).astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf50c320",
   "metadata": {},
   "source": [
    "user_features_sparse = scipy.sparse.csr_matrix(\n",
    "    user_features.loc[interactions.user_to_index.keys()][[\n",
    "        \"13_percent\",\n",
    "        \"18_percent\",\n",
    "        \"citymobil_percent\",\n",
    "        \"takeaway_percent\",\n",
    "        \"discount_percent_mean\",\n",
    "        \"star_rating_mean\"\n",
    "    ]].fillna(0).astype(bool).astype(int).values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "638a4c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1394062x24 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9180625 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "babb9b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fastparquet\n",
    "h3index = H3Index('../data/raw/h3_to_chains.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2fab7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial validation dataset size: 2300001\n",
      "Filter h3 indices that not in h3_to_chain dict 2293762\n",
      "Filter users 483567\n",
      "Filter chains 341552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>h3</th>\n",
       "      <th>chain_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>89118108b43ffff</td>\n",
       "      <td>{28720}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>89118134503ffff</td>\n",
       "      <td>{28720}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>89118134513ffff</td>\n",
       "      <td>{28720}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>89118134517ffff</td>\n",
       "      <td>{28720}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8911813456bffff</td>\n",
       "      <td>{28720}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id               h3 chain_id\n",
       "0        0  89118108b43ffff  {28720}\n",
       "1        0  89118134503ffff  {28720}\n",
       "2        0  89118134513ffff  {28720}\n",
       "3        0  89118134517ffff  {28720}\n",
       "4        0  8911813456bffff  {28720}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_pickle('../data/raw/test_VALID.pkl')\n",
    "val_df = val_df[['customer_id', 'h3', 'chain_id']]\n",
    "val_df = val_df.rename(columns={\"customer_id\": \"user_id\"})\n",
    "val_df.user_id = val_df.user_id.astype(int)\n",
    "print(\"Initial validation dataset size:\", len(val_df))\n",
    "val_df = val_df[val_df[\"h3\"].isin(h3index.valid)]\n",
    "print(\"Filter h3 indices that not in h3_to_chain dict\", len(val_df))\n",
    "val_df = val_df[val_df[\"user_id\"].isin(interactions.user_to_index)]\n",
    "print(\"Filter users\", len(val_df))\n",
    "val_df = val_df[val_df[\"chain_id\"].isin(interactions.chain_to_index)]\n",
    "print(\"Filter chains\", len(val_df))\n",
    "val_df = pd.pivot_table(val_df,\n",
    "                        values=['chain_id'],\n",
    "                        index=['user_id', 'h3'],\n",
    "                        aggfunc={'chain_id': set})\n",
    "val_df = val_df.reset_index()\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "620c89cf",
   "metadata": {},
   "source": [
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "precision = precision_at_k(model, interactions.sparse_interaction_matrix.T, k=30)\n",
    "precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4462b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e919ab0a",
   "metadata": {},
   "source": [
    "### Если h3 пользователя неизвестен, то можно брать следующий в иерархии h3 (более крупный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "852fe603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, user_id, h3, top_k=10):\n",
    "    user_index = interactions.user_to_index[user_id]\n",
    "    valid_chains = h3index.h3_to_chains[h3]\n",
    "    valid_chain_index = [v for k, v in interactions.chain_to_index.items() if k in valid_chains]\n",
    "    pred = model.predict(user_index, valid_chain_index, user_features=user_features_sparse, num_threads=4)\n",
    "    top_chain_index = [x for _, x in sorted(zip(pred, valid_chain_index), reverse=True)][:top_k]\n",
    "    top = [interactions.index_to_chain[k] for k in top_chain_index]\n",
    "    return top\n",
    "\n",
    "def old_items(user_id):\n",
    "    return set(interactions.interaction_df[interactions.interaction_df['user_id'] == user_id]['chain_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e278e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred, y_old, at1=10, at2=30, average=True):\n",
    "    \"\"\"\n",
    "    new_prec@10 + new_prec@30 + 1/2 *(prec_@10 + prec@30)\n",
    "    \"\"\"\n",
    "    scores_new = []\n",
    "    scores_all = []\n",
    "    scores_total = []\n",
    "    for t, p, o in zip(y_true, y_pred, y_old):\n",
    "        t = list(t)\n",
    "        p = list(p)\n",
    "        o = o if isinstance(o, (set, list)) else []\n",
    "        \n",
    "        prec1 = len(set(t[:at1]) & set(p[:at1])) / at1\n",
    "        prec2 = len(set(t[:at2]) & set(p[:at2])) / at2\n",
    "        new_prec1 = len((set(p[:at1]) - set(o)) & set(t[:at1])) / at1\n",
    "        new_prec2 = len((set(p[:at2]) - set(o)) & set(t[:at2])) / at2\n",
    "\n",
    "        scores_total.append(new_prec1 + new_prec2 + 0.5 * (prec1 + prec2))\n",
    "        scores_new.append(new_prec1 + new_prec2)\n",
    "        scores_all.append(prec1 + prec2)\n",
    "\n",
    "    return (np.mean(scores_total) if average else scores_total,\n",
    "            np.mean(scores_new) if average else scores_new,\n",
    "            np.mean(scores_all) if average else scores_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b0dfc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install implicit\n",
    "import implicit\n",
    "\n",
    "def hyper_params(val_df, epochs=60, top_k=30):\n",
    "    #print('factors: ', factors, ', thr: ', thr, ', top_k: ', top_k, ', filter_liked: ', filter_liked)\n",
    "    model = LightFM(loss='warp', user_alpha=0.1)\n",
    "    model.fit(\n",
    "        interactions.sparse_interaction_matrix.T, \n",
    "        user_features=user_features_sparse, \n",
    "        epochs=epochs, num_threads=4\n",
    "    )\n",
    "    val = val_df\n",
    "    val['pred_chains'] = val.apply(lambda x: predict(model, x.user_id, x.h3, top_k), axis=1)\n",
    "    val['old_chains'] = val.apply(lambda x: old_items(x.user_id), axis=1)\n",
    "    scores = metric(val['chain_id'], val['pred_chains'], val['old_chains'])\n",
    "    print('total, new, all = ', scores)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de01f9e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, new, all =  (0.08375840480289043, 0.03254397569949924, 0.10242885820678242)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyper_params(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54ff60b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, new, all =  (0.16267924153184724, 0.07506150749273093, 0.17523546807823256)\n"
     ]
    }
   ],
   "source": [
    "scores = metric(val_df['chain_id'], val_df['chain_id'], val_df['old_chains'])\n",
    "print('total, new, all = ', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa76271e",
   "metadata": {},
   "source": [
    "LightFM без фичей\n",
    "epochs=60, top_k=30\n",
    "\n",
    "total, new, all =  (0.08583693873624455, 0.03078052077852865, 0.11011283591543182)\n",
    "\n",
    "LightFM c несколькими фичами\n",
    "\n",
    "total, new, all =  (0.0822435945227267, 0.032637490991326824, 0.09921220706279976)\n",
    "\n",
    "LightFM с сравнениями со средними  \n",
    "user_alpha=0.1\n",
    "\n",
    "total, new, all =  (0.08338800666020525, 0.03301026367454459, 0.10075548597132136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22156cf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for factors in [30, 40, 50, 60, 70]:\n",
    "    for thr in [0.7, 0.75, 0.8, 0.85, 0.9]:\n",
    "        for top_k in [5, 10, 20, 30]:\n",
    "            for filter_liked in [True, False]:\n",
    "                hyper_params(val_df, factors, thr, top_k, filter_liked) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
