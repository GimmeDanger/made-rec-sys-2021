{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df56dce",
   "metadata": {},
   "source": [
    "# Alternating Least Square (ALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f65b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from interaction_table import ncf_clicks_weigher, ncf_orders_weigher, orders_weigher_sum, InteractionTable\n",
    "from process_data import preprocess_orders_and_clicks, additional_filtration_orders_and_clicks\n",
    "from h3_index import H3Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52fd6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fastparquet\n",
    "h3index = H3Index('../data/h3_to_chains.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86ad018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p ../data/moscow_slice\n",
    "# preprocess_orders_and_clicks(\n",
    "#     path_to_orders=\"../data/orders\",\n",
    "#     path_to_clicks=\"../data/clicks\",\n",
    "#     save_path=\"../data/moscow_slice\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9450cf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clicks():\n",
    "    path = '../data/clicks/'\n",
    "    clicks = pd.read_parquet(f'{path}/clicks.parquet')\n",
    "    return clicks\n",
    "\n",
    "def get_orders():\n",
    "    path = '../data/moscow_slice/'\n",
    "    orders = pd.read_parquet(f'{path}/orders.parquet')\n",
    "    orders = orders.rename(columns={\"customer_id\": \"user_id\"})\n",
    "    clicks = pd.read_parquet(f'{path}/clicks.parquet')\n",
    "    #regs = pd.read_pickle('../data/CITIES_MAPPING.pkl')\n",
    "    #regs = [v for k, v in regs.items() if v > 2]\n",
    "    regs = [1] # moscow\n",
    "    orders, _ = additional_filtration_orders_and_clicks(orders, clicks, regs_to_filter=regs)\n",
    "    return orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98a9f1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders df loaded: size=5452738,  uniq_users=1394011,  uniq_chains=7269\n",
      "Orders df weighted: size=5452738, uniq_users=1394011, uniq_chains=7269\n"
     ]
    }
   ],
   "source": [
    "interactions = InteractionTable(None, get_orders,\n",
    "                                None, ncf_orders_weigher,\n",
    "                                alpha=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5ac61ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7269x1394011 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3105842 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions.sparse_interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8984289a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncf_interactions: 3143215\n",
      "ncf_uniq_users: 263989\n",
      "ncf_uniq_chains: 7122\n"
     ]
    }
   ],
   "source": [
    "test = interactions.interaction_df[['user_id', 'weight']]\n",
    "test = test.groupby('user_id').sum()\n",
    "test = test.reset_index()[['user_id', 'weight']]\n",
    "user_with_few_interactions = set(test[test['weight'] <= 5].user_id.unique())\n",
    "ncf_interactions = interactions.interaction_df.query('user_id not in @user_with_few_interactions')\n",
    "ncf_interactions.to_parquet('../data/moscow_slice/ncf_orders.parquet')\n",
    "print(\"ncf_interactions:\", len(ncf_interactions))\n",
    "\n",
    "ncf_valid_users = set(ncf_interactions['user_id'].unique())\n",
    "print(\"ncf_uniq_users:\", len(ncf_valid_users))\n",
    "ncf_valid_chains = set(ncf_interactions['chain_id'].unique())\n",
    "print(\"ncf_uniq_chains:\", len(ncf_valid_chains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "705f8949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial:\n",
      "df, uniq_users, uniq_chains: 2300001 1253198 19810\n",
      "\n",
      "after invalid h3 filtering:\n",
      "df, uniq_users, uniq_chains: 2293762 1249258 19788\n",
      "\n",
      "after invalid users filtering:\n",
      "df, uniq_users, uniq_chains: 483559 212160 11404\n",
      "\n",
      "after invalid chains filtering:\n",
      "df, uniq_users, uniq_chains: 341373 172590 5297\n",
      "\n",
      "after dropping duplicates:\n",
      "df, uniq_users, uniq_chains: 256964 172590 5297\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.read_pickle('../data/test_VALID.pkl')\n",
    "val_df = val_df[['customer_id', 'h3', 'chain_id']]\n",
    "val_df = val_df.rename(columns={\"customer_id\": \"user_id\"})\n",
    "val_df.user_id = val_df.user_id.astype(int)\n",
    "print(\"initial:\")\n",
    "print(\"df, uniq_users, uniq_chains:\", len(val_df), len(val_df.user_id.unique()), len(val_df.chain_id.unique()))\n",
    "\n",
    "val_df = val_df.query('h3 in @h3index.valid')\n",
    "print()\n",
    "print(\"after invalid h3 filtering:\")\n",
    "print(\"df, uniq_users, uniq_chains:\", len(val_df), len(val_df.user_id.unique()), len(val_df.chain_id.unique()))\n",
    "\n",
    "val_df = val_df.query('user_id in @interactions.user_index')\n",
    "print()\n",
    "print(\"after invalid users filtering:\")\n",
    "print(\"df, uniq_users, uniq_chains:\", len(val_df), len(val_df.user_id.unique()), len(val_df.chain_id.unique()))\n",
    "\n",
    "val_df = val_df.query('chain_id in @interactions.chain_index')\n",
    "print()\n",
    "print(\"after invalid chains filtering:\")\n",
    "print(\"df, uniq_users, uniq_chains:\", len(val_df), len(val_df.user_id.unique()), len(val_df.chain_id.unique()))\n",
    "\n",
    "val_df = val_df.drop_duplicates()\n",
    "print()\n",
    "print(\"after dropping duplicates:\")\n",
    "print(\"df, uniq_users, uniq_chains:\", len(val_df), len(val_df.user_id.unique()), len(val_df.chain_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7461311d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>h3</th>\n",
       "      <th>chain_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>386249</td>\n",
       "      <td>8911aa7aa1bffff</td>\n",
       "      <td>29454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59217420</td>\n",
       "      <td>8911aa4c867ffff</td>\n",
       "      <td>45822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>8911aa70a97ffff</td>\n",
       "      <td>28720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8980391</td>\n",
       "      <td>8911aa09b4bffff</td>\n",
       "      <td>53904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8298875</td>\n",
       "      <td>8911aa70b2fffff</td>\n",
       "      <td>29454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id               h3  chain_id\n",
       "0     386249  8911aa7aa1bffff     29454\n",
       "2   59217420  8911aa4c867ffff     45822\n",
       "11         0  8911aa70a97ffff     28720\n",
       "14   8980391  8911aa09b4bffff     53904\n",
       "19   8298875  8911aa70b2fffff     29454"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7c9fa56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 691/172590 [04:32<18:50:20,  2.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-3acf03172320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mother_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# not presented in val_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mother_data_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mncf_val_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_data_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df, uniq_users, uniq_chains:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncf_val_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncf_val_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncf_val_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mncf_val_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/moscow_slice/ncf_pred_interactions.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/home/scripts/env/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    296\u001b[0m     )\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/home/scripts/env/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    518\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             new_data = concatenate_block_managers(\n\u001b[0m\u001b[1;32m    521\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             )\n",
      "\u001b[0;32m~/home/scripts/env/lib/python3.8/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_extension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;31m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/home/scripts/env/lib/python3.8/site-packages/pandas/core/dtypes/concat.py\u001b[0m in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# prepare for ncf\n",
    "ncf_val_df = pd.DataFrame()\n",
    "for user_id in tqdm(val_df.user_id.unique()):\n",
    "    user_data = pd.DataFrame(val_df[val_df['user_id'] == user_id])\n",
    "    user_data['label'] = 1 # presented in val_df\n",
    "    other_data_lst = [ncf_val_df, user_data]\n",
    "    for user_h3 in user_data['h3'].unique():\n",
    "        user_chains = set(user_data[user_data['h3'] == h3].chain_id.unique())\n",
    "        other_chains = set(h3index.h3_to_chains[user_h3])\n",
    "        other_chains = other_chains.difference(user_chains)\n",
    "        other_data = pd.DataFrame(other_chains, columns=['chain_id'])\n",
    "        other_data['user_id'] = user_id\n",
    "        other_data['h3'] = user_h3\n",
    "        other_data['label'] = 0 # not presented in val_df\n",
    "        other_data_lst.append(other_data)\n",
    "    ncf_val_df = pd.concat(other_data_lst, ignore_index=True, sort=False)\n",
    "print(\"df, uniq_users, uniq_chains:\", len(ncf_val_df), len(ncf_val_df.user_id.unique()), len(ncf_val_df.chain_id.unique()))\n",
    "ncf_val_df.to_parquet('../data/moscow_slice/ncf_pred_interactions.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeae53d",
   "metadata": {},
   "source": [
    "## Сколько данных тестовой выборки отсеивается в зависимости от interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4c4363",
   "metadata": {},
   "source": [
    "### Clicks + orders: full\n",
    "\n",
    "initial:\n",
    "df, uniq_users, uniq_chains: 2300001 1253198 19810\n",
    "\n",
    "after invalid h3 filtering:\n",
    "df, uniq_users, uniq_chains: 2293762 1249258 19788\n",
    "\n",
    "after invalid users filtering:\n",
    "df, uniq_users, uniq_chains: 1987082 1044374 19453\n",
    "\n",
    "after invalid chains filtering:\n",
    "df, uniq_users, uniq_chains: 1984220 1043382 19118\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8484d648",
   "metadata": {},
   "source": [
    "### Orders: full\n",
    "\n",
    "initial:\n",
    "df, uniq_users, uniq_chains: 2300001 1253198 19810\n",
    "\n",
    "after invalid h3 filtering:\n",
    "df, uniq_users, uniq_chains: 2293762 1249258 19788\n",
    "\n",
    "after invalid users filtering:\n",
    "df, uniq_users, uniq_chains: 1860055 952741 19285\n",
    "\n",
    "after invalid chains filtering:\n",
    "df, uniq_users, uniq_chains: 1856314 951570 18664"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722d326b",
   "metadata": {},
   "source": [
    "### Clicks + orders: processed full\n",
    "\n",
    "initial:\n",
    "df, uniq_users, uniq_chains: 2300001 1253198 19810\n",
    "\n",
    "after invalid h3 filtering:\n",
    "df, uniq_users, uniq_chains: 2293762 1249258 19788\n",
    "\n",
    "after invalid users filtering:\n",
    "df, uniq_users, uniq_chains: 851440 415267 17272\n",
    "\n",
    "after invalid chains filtering:\n",
    "df, uniq_users, uniq_chains: 692249 369776 16446"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7b830",
   "metadata": {},
   "source": [
    "### Orders: processed moscow\n",
    "\n",
    "initial:\n",
    "df, uniq_users, uniq_chains: 2300001 1253198 19810\n",
    "\n",
    "after invalid h3 filtering:\n",
    "df, uniq_users, uniq_chains: 2293762 1249258 19788\n",
    "\n",
    "after invalid users filtering:\n",
    "df, uniq_users, uniq_chains: 483559 212160 11404\n",
    "\n",
    "after invalid chains filtering:\n",
    "df, uniq_users, uniq_chains: 341373 172590 5297"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efa1982",
   "metadata": {},
   "source": [
    "### Orders: processed saint-peterburg\n",
    "initial:\n",
    "df, uniq_users, uniq_chains: 2300001 1253198 19810\n",
    "\n",
    "after invalid h3 filtering:\n",
    "df, uniq_users, uniq_chains: 2293762 1249258 19788\n",
    "\n",
    "after invalid users filtering:\n",
    "df, uniq_users, uniq_chains: 164699 62373 5801\n",
    "\n",
    "after invalid chains filtering:\n",
    "df, uniq_users, uniq_chains: 87146 46513 1384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eca2fa",
   "metadata": {},
   "source": [
    "### Orders: processed other regions\n",
    "\n",
    "initial:\n",
    "df, uniq_users, uniq_chains: 2300001 1253198 19810\n",
    "\n",
    "after invalid h3 filtering:\n",
    "df, uniq_users, uniq_chains: 2293762 1249258 19788\n",
    "\n",
    "after invalid users filtering:\n",
    "df, uniq_users, uniq_chains: 376063 178911 13700\n",
    "\n",
    "after invalid chains filtering:\n",
    "df, uniq_users, uniq_chains: 240902 136697 9381"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af15a29",
   "metadata": {},
   "source": [
    "# Выводы:\n",
    "* 20% тестовых юзеров нет ни в clicks, ни в orders (cold start);\n",
    "* 75% тестовых юзеров есть в orders, т.е clicks можно не рассматривать (всего 5%);\n",
    "* только 30% (!!!!) тестовых юзеров остается после вызова processed_data;\n",
    "* 48% -- москва, 39% -- регионы, 13% -- спб в orders после вызова processed_data;\n",
    "* также есть сделать val.drop_duplicates, то отсортируется порядка 30% строк!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e919ab0a",
   "metadata": {},
   "source": [
    "### Если h3 пользователя неизвестен, то можно брать следующий в иерархии h3 (более крупный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade07e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.pivot_table(val_df,\n",
    "                        values=['chain_id'],\n",
    "                        index=['user_id', 'h3'],\n",
    "                        aggfunc={'chain_id': set})\n",
    "val_df = val_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852fe603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, user_id, h3, thr=0.9, top_k=10, filter_already_liked_items=True):\n",
    "    user_index = interactions.user_index[user_id]\n",
    "    valid_chains = h3index.h3_to_chains[h3]\n",
    "    filter_items = [v for k, v in interactions.chain_index.items() if k not in valid_chains]\n",
    "    top = model.recommend(user_index,\n",
    "                          interactions.sparse_interaction_matrix.T,\n",
    "                          N=top_k,\n",
    "                          filter_already_liked_items=filter_already_liked_items,\n",
    "                          filter_items=filter_items)\n",
    "    top = [interactions.r_chain_index[x] for x, score in top if score > thr]\n",
    "    return top\n",
    "\n",
    "def old_items(user_id):\n",
    "    return set(interactions.interaction_df[interactions.interaction_df['user_id'] == user_id]['chain_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e278e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred, y_old, at1=10, at2=30, average=True):\n",
    "    \"\"\"\n",
    "    new_prec@10 + new_prec@30 + 1/2 *(prec_@10 + prec@30)\n",
    "    \"\"\"\n",
    "    scores_new = []\n",
    "    scores_all = []\n",
    "    scores_total = []\n",
    "    for t, p, o in zip(y_true, y_pred, y_old):\n",
    "        t = list(t)\n",
    "        p = list(p)\n",
    "        o = o if isinstance(o, (set, list)) else []\n",
    "        \n",
    "        prec1 = len(set(t[:at1]) & set(p[:at1])) / at1\n",
    "        prec2 = len(set(t[:at2]) & set(p[:at2])) / at2\n",
    "        new_prec1 = len((set(p[:at1]) - set(o)) & set(t[:at1])) / at1\n",
    "        new_prec2 = len((set(p[:at2]) - set(o)) & set(t[:at2])) / at2\n",
    "\n",
    "        scores_total.append(new_prec1 + new_prec2 + 0.5 * (prec1 + prec2))\n",
    "        scores_new.append(new_prec1 + new_prec2)\n",
    "        scores_all.append(prec1 + prec2)\n",
    "\n",
    "    return (np.mean(scores_total) if average else scores_total,\n",
    "            np.mean(scores_new) if average else scores_new,\n",
    "            np.mean(scores_all) if average else scores_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0dfc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install implicit\n",
    "import implicit\n",
    "\n",
    "def hyper_params(val_df, factors=60, thr=0.7, top_k=30, filter_liked=True):\n",
    "    print('factors: ', factors, ', thr: ', thr, ', top_k: ', top_k, ', filter_liked: ', filter_liked)\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=factors)\n",
    "    model.fit(interactions.sparse_interaction_matrix)\n",
    "    val = val_df\n",
    "    val['pred_chains'] = val.apply(lambda x: predict(model, x.user_id, x.h3, thr, top_k, filter_liked), axis=1)\n",
    "    val['old_chains'] = val.apply(lambda x: old_items(x.user_id), axis=1)\n",
    "    scores = metric(val['chain_id'], val['pred_chains'], val['old_chains'])\n",
    "    print('total, new, all = ', scores)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params(val_df, factors=60, thr=0.7, top_k=30, filter_liked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa76271e",
   "metadata": {},
   "source": [
    "factors:  60 , thr:  0.7 , top_k:  30 , filter_liked:  True\n",
    "\n",
    "total, new, all =  (0.02605082142811052, 0.00023745918670228555, 0.05162672448281647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22156cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for factors in [30, 40, 50, 60, 70]:\n",
    "    for thr in [0.7, 0.75, 0.8, 0.85, 0.9]:\n",
    "        for top_k in [5, 10, 20, 30]:\n",
    "            for filter_liked in [True, False]:\n",
    "               hyper_params(val_df, factors, thr, top_k, filter_liked) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
